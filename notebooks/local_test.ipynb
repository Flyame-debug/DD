{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bf060",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ipython-input-2404118028.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2404118028.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python main.py --mode train --config config/config.yaml --data_dir ./data/chest_xray --output_dir ./outputs_test --epochs 2 --batch_size 4\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# notebooks/local_test.ipynb - 完整的本地测试代码\n",
    "\n",
    "# %% [markdown]\n",
    "# # 胸部X光疾病分类 - 本地完整测试\n",
    "# \n",
    "# 这个笔记本用于在本地全面测试所有代码模块\n",
    "\n",
    "# %%\n",
    "# 安装必要依赖（如果还没安装）\n",
    "# !pip install torch torchvision numpy pandas matplotlib scikit-learn\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = os.path.abspath('..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(f\"项目根目录: {project_root}\")\n",
    "\n",
    "# %%\n",
    "# 1. 测试配置加载\n",
    "print(\"=\"*50)\n",
    "print(\"1. 测试配置加载\")\n",
    "\n",
    "try:\n",
    "    config_path = os.path.join(project_root, 'config/config.yaml')\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # 使用本地路径\n",
    "    config['paths'] = config['paths_local']\n",
    "    \n",
    "    print(\"✓ 配置加载成功\")\n",
    "    print(f\"  配置内容:\")\n",
    "    print(f\"  - 图像大小: {config['data']['image_size']}\")\n",
    "    print(f\"  - 批量大小: {config['training']['batch_size']}\")\n",
    "    print(f\"  - 模型: {config['model']['backbone']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 配置加载失败: {e}\")\n",
    "\n",
    "# %%\n",
    "# 2. 测试数据加载\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. 测试数据加载\")\n",
    "\n",
    "try:\n",
    "    from data.preprocess import load_and_preprocess_data\n",
    "    \n",
    "    # 检查数据文件是否存在\n",
    "    csv_path = config['paths']['csv_path']\n",
    "    images_dir = config['paths']['images_dir']\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"✓ 标签文件存在: {csv_path}\")\n",
    "    else:\n",
    "        print(f\"✗ 标签文件不存在: {csv_path}\")\n",
    "        # 尝试查找文件\n",
    "        csv_files = [f for f in os.listdir(os.path.dirname(csv_path)) if f.endswith('.csv')]\n",
    "        print(f\"  找到的CSV文件: {csv_files}\")\n",
    "    \n",
    "    if os.path.exists(images_dir):\n",
    "        print(f\"✓ 图像目录存在: {images_dir}\")\n",
    "        image_files = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        print(f\"  找到图像数量: {len(image_files[:5])} (显示前5个: {image_files[:5]})\")\n",
    "    else:\n",
    "        print(f\"✗ 图像目录不存在: {images_dir}\")\n",
    "    \n",
    "    # 尝试加载数据（使用小样本测试）\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"\\n✓ 成功加载CSV文件\")\n",
    "        print(f\"  数据形状: {df.shape}\")\n",
    "        print(f\"  列名: {list(df.columns)}\")\n",
    "        \n",
    "        # 显示前几行\n",
    "        print(f\"\\n  数据预览:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # 检查标签列\n",
    "        if len(df.columns) > 1:\n",
    "            print(f\"\\n  标签分布:\")\n",
    "            for col in df.columns[1:5]:  # 只显示前几个标签\n",
    "                if col in df.columns:\n",
    "                    pos_rate = df[col].mean()\n",
    "                    print(f\"  {col}: {pos_rate:.3%} ({df[col].sum()} 正样本)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 数据加载失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 3. 测试数据集类\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. 测试数据集类\")\n",
    "\n",
    "try:\n",
    "    from data.dataset import ChestXRayDataset\n",
    "    from data.dataset import ChestXRayDataset as dataset_class\n",
    "    \n",
    "    # 创建一个小样本DataFrame用于测试\n",
    "    if 'df' in locals() and len(df) > 0:\n",
    "        test_df = df.head(5).copy()\n",
    "        \n",
    "        # 创建数据集实例\n",
    "        test_dataset = dataset_class(\n",
    "            test_df,\n",
    "            config['paths']['images_dir'],\n",
    "            transform=dataset_class.get_transforms(config, 'train'),\n",
    "            phase='train'\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ 数据集类创建成功\")\n",
    "        print(f\"  数据集大小: {len(test_dataset)}\")\n",
    "        \n",
    "        # 测试获取单个样本\n",
    "        try:\n",
    "            image, labels = test_dataset[0]\n",
    "            print(f\"✓ 成功获取样本\")\n",
    "            print(f\"  图像形状: {image.shape}\")\n",
    "            print(f\"  标签形状: {labels.shape}\")\n",
    "            print(f\"  标签值: {labels.numpy()}\")\n",
    "            \n",
    "            # 可视化一个样本\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            \n",
    "            # 显示图像\n",
    "            plt.subplot(1, 2, 1)\n",
    "            # 反归一化图像以便显示\n",
    "            mean = np.array(config['data']['mean'])\n",
    "            std = np.array(config['data']['std'])\n",
    "            img_np = image.numpy().transpose(1, 2, 0)\n",
    "            img_np = std * img_np + mean\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "            plt.imshow(img_np)\n",
    "            plt.title(f\"图像示例\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # 显示标签\n",
    "            plt.subplot(1, 2, 2)\n",
    "            labels_np = labels.numpy()\n",
    "            classes = test_dataset.class_names[:len(labels_np)]\n",
    "            colors = ['red' if l > 0.5 else 'blue' for l in labels_np]\n",
    "            plt.barh(classes, labels_np, color=colors)\n",
    "            plt.xlabel('概率')\n",
    "            plt.title('标签')\n",
    "            plt.xlim([0, 1])\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig('../test_sample.png', dpi=100, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ 获取样本失败: {e}\")\n",
    "            # 尝试查找问题\n",
    "            print(f\"  检查图像路径: {os.path.join(config['paths']['images_dir'], test_df.iloc[0]['Image Index'])}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"✗ 没有可用的数据用于测试\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ 数据集类测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 4. 测试模型创建\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"4. 测试模型创建\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from models.model import DenseNet121MultiLabel\n",
    "    \n",
    "    # 设置设备\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"  使用设备: {device}\")\n",
    "    \n",
    "    # 创建模型\n",
    "    model = DenseNet121MultiLabel(\n",
    "        num_classes=config['model']['num_classes'],\n",
    "        pretrained=False  # 测试时不下载预训练权重，加快速度\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ 模型创建成功\")\n",
    "    \n",
    "    # 测试模型前向传播\n",
    "    batch_size = 2\n",
    "    test_input = torch.randn(batch_size, 3, 512, 512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(test_input)\n",
    "        \n",
    "        print(f\"✓ 前向传播测试成功\")\n",
    "        print(f\"  输入形状: {test_input.shape}\")\n",
    "        print(f\"  输出形状: {output.shape}\")\n",
    "        print(f\"  输出范围: {output.min().item():.4f} 到 {output.max().item():.4f}\")\n",
    "        print(f\"  输出示例: {output[0, :5].numpy()}\")  # 显示前5个输出\n",
    "        \n",
    "    # 计算参数量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\n  模型参数统计:\")\n",
    "    print(f\"  总参数量: {total_params:,}\")\n",
    "    print(f\"  可训练参数量: {trainable_params:,}\")\n",
    "    print(f\"  不可训练参数量: {total_params - trainable_params:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 模型测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 5. 测试数据加载器\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. 测试数据加载器\")\n",
    "\n",
    "try:\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    if 'test_dataset' in locals():\n",
    "        # 创建数据加载器\n",
    "        dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=min(2, len(test_dataset)),  # 小批量\n",
    "            shuffle=True,\n",
    "            num_workers=0  # 测试时设为0避免问题\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ 数据加载器创建成功\")\n",
    "        \n",
    "        # 测试一个批次\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            print(f\"  批次 {batch_idx}:\")\n",
    "            print(f\"    图像形状: {images.shape}\")\n",
    "            print(f\"    标签形状: {labels.shape}\")\n",
    "            \n",
    "            # 显示批次统计\n",
    "            print(f\"    标签统计 - 每个类别的正样本数:\")\n",
    "            for i in range(labels.shape[1]):\n",
    "                pos_count = labels[:, i].sum().item()\n",
    "                if pos_count > 0:\n",
    "                    class_name = test_dataset.class_names[i] if i < len(test_dataset.class_names) else f\"Class_{i}\"\n",
    "                    print(f\"      {class_name}: {pos_count}/{labels.shape[0]}\")\n",
    "            \n",
    "            # 只测试第一个批次\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n✓ 数据加载器测试通过\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ 数据加载器测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 6. 测试损失函数和优化器\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. 测试训练组件\")\n",
    "\n",
    "try:\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    \n",
    "    # 创建简单的模型和数据\n",
    "    test_model = DenseNet121MultiLabel(num_classes=5, pretrained=False)\n",
    "    test_input = torch.randn(2, 3, 224, 224)\n",
    "    test_target = torch.randint(0, 2, (2, 5)).float()\n",
    "    \n",
    "    # 测试损失函数\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(test_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # 训练步骤\n",
    "    optimizer.zero_grad()\n",
    "    output = test_model(test_input)\n",
    "    loss = criterion(output, test_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"✓ 训练步骤测试成功\")\n",
    "    print(f\"  损失值: {loss.item():.6f}\")\n",
    "    \n",
    "    # 测试自定义损失函数（如果存在）\n",
    "    try:\n",
    "        from training.losses import WeightedBCELoss, FocalLoss\n",
    "        \n",
    "        # 测试加权BCE损失\n",
    "        pos_weight = torch.tensor([1.0, 2.0, 1.0, 1.0, 1.0])\n",
    "        weighted_criterion = WeightedBCELoss(pos_weight=pos_weight)\n",
    "        weighted_loss = weighted_criterion(output, test_target)\n",
    "        print(f\"✓ 加权BCE损失测试成功: {weighted_loss.item():.6f}\")\n",
    "        \n",
    "        # 测试Focal Loss\n",
    "        focal_criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "        focal_loss = focal_criterion(output, test_target)\n",
    "        print(f\"✓ Focal Loss测试成功: {focal_loss.item():.6f}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(f\"⚠ 自定义损失函数未找到，跳过测试\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 训练组件测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 7. 测试评估指标\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"7. 测试评估指标\")\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score, f1_score\n",
    "    \n",
    "    # 生成模拟的预测和标签\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    n_classes = 5\n",
    "    \n",
    "    y_true = np.random.randint(0, 2, (n_samples, n_classes))\n",
    "    y_pred = np.random.rand(n_samples, n_classes)\n",
    "    \n",
    "    # 计算指标\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        if len(np.unique(y_true[:, i])) > 1:\n",
    "            auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "            auc_scores.append(auc)\n",
    "        \n",
    "        f1 = f1_score(y_true[:, i], (y_pred[:, i] > 0.5).astype(int))\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    print(f\"✓ 评估指标计算成功\")\n",
    "    print(f\"  AUC分数: {np.mean(auc_scores):.4f}\")\n",
    "    print(f\"  F1分数: {np.mean(f1_scores):.4f}\")\n",
    "    \n",
    "    # 测试项目中的指标计算函数\n",
    "    try:\n",
    "        from training.metrics import calculate_metrics\n",
    "        metrics = calculate_metrics(y_true, y_pred, threshold=0.5)\n",
    "        print(f\"✓ 项目指标函数测试成功\")\n",
    "        print(f\"  平均AUC: {metrics['auc_mean']:.4f}\")\n",
    "        print(f\"  平均F1: {metrics['f1_mean']:.4f}\")\n",
    "    except ImportError:\n",
    "        print(f\"⚠ 项目指标函数未找到，跳过测试\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 评估指标测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 8. 测试完整训练流程（最小版本）\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"8. 测试完整训练流程\")\n",
    "\n",
    "try:\n",
    "    # 创建一个极小的训练循环进行测试\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    \n",
    "    # 创建模拟数据\n",
    "    n_samples = 10\n",
    "    n_features = 3 * 224 * 224  # 简化输入\n",
    "    n_classes = 5\n",
    "    \n",
    "    # 模拟图像数据 (10张224x224的RGB图像)\n",
    "    X = torch.randn(n_samples, 3, 224, 224)\n",
    "    y = torch.randint(0, 2, (n_samples, n_classes)).float()\n",
    "    \n",
    "    # 创建数据集和数据加载器\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    # 创建简单模型\n",
    "    class SimpleModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "            self.pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "            self.fc = torch.nn.Linear(16, n_classes)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "            return self.sigmoid(x)\n",
    "    \n",
    "    model = SimpleModel()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # 训练1个epoch\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"  批次 {batch_idx}: 损失 = {loss.item():.6f}\")\n",
    "        \n",
    "        # 只运行一个批次测试\n",
    "        if batch_idx == 0:\n",
    "            break\n",
    "    \n",
    "    print(f\"✓ 最小训练流程测试成功\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 训练流程测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 9. 测试可视化函数\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"9. 测试可视化函数\")\n",
    "\n",
    "try:\n",
    "    # 生成一些测试数据用于可视化\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 模拟训练历史\n",
    "    history = {\n",
    "        'train_loss': [1.0, 0.8, 0.6, 0.5, 0.45, 0.4, 0.38, 0.36, 0.35, 0.34],\n",
    "        'val_loss': [1.1, 0.9, 0.7, 0.6, 0.55, 0.5, 0.48, 0.47, 0.46, 0.45],\n",
    "        'train_auc': [0.5, 0.6, 0.7, 0.75, 0.78, 0.8, 0.82, 0.83, 0.84, 0.85],\n",
    "        'val_auc': [0.5, 0.58, 0.65, 0.7, 0.73, 0.75, 0.77, 0.78, 0.79, 0.8],\n",
    "        'train_f1': [0.4, 0.5, 0.55, 0.6, 0.63, 0.65, 0.67, 0.68, 0.69, 0.7],\n",
    "        'val_f1': [0.38, 0.45, 0.5, 0.55, 0.58, 0.6, 0.62, 0.63, 0.64, 0.65]\n",
    "    }\n",
    "    \n",
    "    # 测试可视化函数\n",
    "    try:\n",
    "        from utils.visualization import plot_training_history\n",
    "        \n",
    "        # 创建输出目录\n",
    "        output_dir = \"../test_outputs\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 绘制训练历史\n",
    "        plot_training_history(history, output_dir)\n",
    "        print(f\"✓ 训练历史可视化成功\")\n",
    "        print(f\"  图像保存到: {output_dir}\")\n",
    "        \n",
    "        # 检查文件是否存在\n",
    "        history_path = os.path.join(output_dir, 'training_history.png')\n",
    "        if os.path.exists(history_path):\n",
    "            print(f\"✓ 训练历史图像文件已生成\")\n",
    "            \n",
    "            # 显示图像\n",
    "            img = plt.imread(history_path)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('训练历史图像预览')\n",
    "            plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(f\"⚠ 可视化函数未找到，跳过测试\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ 可视化测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %%\n",
    "# 10. 总结测试结果\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"测试完成总结\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n✓ 本地测试已完成！\")\n",
    "print(\"\\n下一步建议:\")\n",
    "print(\"1. 如果所有测试都通过，可以开始完整训练\")\n",
    "print(\"2. 如果有测试失败，请根据错误信息修复代码\")\n",
    "print(\"3. 确保数据路径配置正确\")\n",
    "print(\"4. 确保所有依赖包已安装\")\n",
    "\n",
    "# 创建requirements检查\n",
    "print(\"\\n依赖包检查:\")\n",
    "required_packages = ['torch', 'torchvision', 'numpy', 'pandas', \n",
    "                     'matplotlib', 'scikit-learn', 'scikit-image',\n",
    "                     'Pillow', 'pyyaml', 'tqdm']\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"  ✓ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ✗ {package} 未安装\")\n",
    "\n",
    "print(\"\\n运行以下命令安装缺少的包:\")\n",
    "print(\"pip install torch torchvision numpy pandas matplotlib scikit-learn scikit-image Pillow pyyaml tqdm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
